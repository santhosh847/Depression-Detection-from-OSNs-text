{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Convolution1D, GlobalMaxPooling1D\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import seaborn as sns\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import ssl\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            message  label\n",
      "0           0  The lack of this understanding is a small but ...      1\n",
      "1           1  i just told my parents about my depression and...      1\n",
      "2           2  depression is something i don't speak about ev...      1\n",
      "3           3  Made myself a tortilla filled with pb&j. My de...      1\n",
      "4           4  @WorldofOutlaws I am gonna need depression med...      1\n",
      "5           5  my anxiety and my depression fighting over who...      1\n",
      "6           6  wow she's suddenly cured my depression and gav...      1\n",
      "7           7  I am officially done with @kanyewest. him, the...      1\n",
      "8           8  Me: what's wrong?My girl: *looks up at me with...      1\n",
      "9           9  @AusBorderForce @PeterDutton_MP @shanebazzi Ag...      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('d1.csv')\n",
    "print(df.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/santhosh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=True):\n",
    "    # Remove link,user and special characters\n",
    "    TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            message  label\n",
      "0           0  The lack of this understanding is a small but ...      1\n",
      "1           1  i just told my parents about my depression and...      1\n",
      "2           2  depression is something i don't speak about ev...      1\n",
      "3           3  Made myself a tortilla filled with pb&j. My de...      1\n",
      "4           4  @WorldofOutlaws I am gonna need depression med...      1\n",
      "after preprocessing\n",
      "   Unnamed: 0                                            message  label\n",
      "0           0  lack understand small signific part caus anxie...      1\n",
      "1           1  told parent depress hard get gen x peopl under...      1\n",
      "2           2  depress someth speak even go also doubl edg sw...      1\n",
      "3           3  made tortilla fill pb j depress cure olivia 1 ...      1\n",
      "4           4  gonna need depress med soon rainout spin equil...      1\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "df.message = df.message.apply(lambda x: preprocess(x))\n",
    "\n",
    "print(\"after preprocessing\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.message.to_numpy()\n",
    "labels = df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer with maximum features set to 1000\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit and transform the texts into TF-IDF features\n",
    "tfidf_features = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Set the maximum sequence length to the number of features in the TF-IDF matrix\n",
    "max_len = tfidf_features.shape[1]\n",
    "\n",
    "# Split the dataset into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=tfidf_features.shape[1], output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 23:55:50.400272: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 178s 3s/step - loss: 0.5976 - accuracy: 0.6433 - val_loss: 0.5616 - val_accuracy: 0.6652\n",
      "Epoch 2/8\n",
      "51/51 [==============================] - 412s 8s/step - loss: 0.5738 - accuracy: 0.6740 - val_loss: 0.5770 - val_accuracy: 0.6450\n",
      "Epoch 3/8\n",
      "51/51 [==============================] - 535s 11s/step - loss: 0.5709 - accuracy: 0.6743 - val_loss: 0.5669 - val_accuracy: 0.6652\n",
      "Epoch 4/8\n",
      "51/51 [==============================] - 127s 2s/step - loss: 0.5686 - accuracy: 0.6726 - val_loss: 0.5659 - val_accuracy: 0.6652\n",
      "Epoch 5/8\n",
      "51/51 [==============================] - 141s 3s/step - loss: 0.5692 - accuracy: 0.6769 - val_loss: 0.5596 - val_accuracy: 0.6652\n",
      "Epoch 6/8\n",
      "51/51 [==============================] - 133s 3s/step - loss: 0.5696 - accuracy: 0.6755 - val_loss: 0.5666 - val_accuracy: 0.6652\n",
      "Epoch 7/8\n",
      "51/51 [==============================] - 129s 3s/step - loss: 0.5683 - accuracy: 0.6735 - val_loss: 0.5693 - val_accuracy: 0.6652\n",
      "Epoch 8/8\n",
      "51/51 [==============================] - 125s 2s/step - loss: 0.5688 - accuracy: 0.6711 - val_loss: 0.5674 - val_accuracy: 0.6652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280c90e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "model.fit(X_train.toarray(), y_train, epochs=8, batch_size=128, validation_data=(X_test.toarray(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631/1631 [==============================] - 48s 29ms/step - loss: 0.5674 - accuracy: 0.6652\n",
      "Test Loss: 0.5674421191215515\n",
      "Test Accuracy: 0.6652360558509827\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the LSTM model\n",
    "loss, accuracy = model.evaluate(X_test.toarray(), y_test, batch_size=1)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 10s 187ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.77      0.65       649\n",
      "           1       0.80      0.60      0.68       982\n",
      "\n",
      "    accuracy                           0.67      1631\n",
      "   macro avg       0.68      0.68      0.66      1631\n",
      "weighted avg       0.70      0.67      0.67      1631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred = model.predict(X_test.toarray())\n",
    "labels_pred = np.round(labels_pred.flatten())\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            tokens.append(stemmer.stem(token))\n",
    "    text = \" \".join(tokens)\n",
    "    text = np.array([text])\n",
    "    text = vectorizer.transform(text)\n",
    "    return \"POSITIVE\" if model.predict(text.toarray()) > 0.5 else \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"depression is real, life is very hard, i hate everything, suicide is only way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i enjoyed the vacations, i loved listening to songs when i was in vacation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(tfidf_features.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.toarray().reshape(X_train.shape[0], tfidf_features.shape[1], 1)\n",
    "X_test_reshaped = X_test.toarray().reshape(X_test.shape[0], tfidf_features.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6524/6524 [==============================] - 18s 3ms/step - loss: 0.3519 - accuracy: 0.8351 - val_loss: 0.1523 - val_accuracy: 0.9430\n",
      "Epoch 2/10\n",
      "6524/6524 [==============================] - 17s 3ms/step - loss: 0.1491 - accuracy: 0.9460 - val_loss: 0.1456 - val_accuracy: 0.9418\n",
      "Epoch 3/10\n",
      "6524/6524 [==============================] - 17s 3ms/step - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.1513 - val_accuracy: 0.9467\n",
      "Epoch 4/10\n",
      "6524/6524 [==============================] - 16s 3ms/step - loss: 0.1322 - accuracy: 0.9491 - val_loss: 0.1205 - val_accuracy: 0.9546\n",
      "Epoch 5/10\n",
      "6524/6524 [==============================] - 16s 2ms/step - loss: 0.1220 - accuracy: 0.9552 - val_loss: 0.1152 - val_accuracy: 0.9552\n",
      "Epoch 6/10\n",
      "6524/6524 [==============================] - 16s 3ms/step - loss: 0.1184 - accuracy: 0.9536 - val_loss: 0.1386 - val_accuracy: 0.9454\n",
      "Epoch 7/10\n",
      "6524/6524 [==============================] - 16s 2ms/step - loss: 0.1181 - accuracy: 0.9546 - val_loss: 0.1358 - val_accuracy: 0.9491\n",
      "Epoch 8/10\n",
      "6524/6524 [==============================] - 16s 2ms/step - loss: 0.1163 - accuracy: 0.9552 - val_loss: 0.1270 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "6524/6524 [==============================] - 16s 2ms/step - loss: 0.1136 - accuracy: 0.9582 - val_loss: 0.1274 - val_accuracy: 0.9516\n",
      "Epoch 10/10\n",
      "6524/6524 [==============================] - 16s 2ms/step - loss: 0.1111 - accuracy: 0.9588 - val_loss: 0.1200 - val_accuracy: 0.9510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fd52aa0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=1, validation_data=(X_test_reshaped, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       649\n",
      "           1       0.98      0.94      0.96       982\n",
      "\n",
      "    accuracy                           0.95      1631\n",
      "   macro avg       0.95      0.95      0.95      1631\n",
      "weighted avg       0.95      0.95      0.95      1631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred = model.predict(X_test_reshaped)\n",
    "labels_pred = np.round(labels_pred.flatten())\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(tfidf_features.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 998, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 499, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 497, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 248, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,673\n",
      "Trainable params: 156,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6524/6524 [==============================] - 277s 42ms/step - loss: 0.6878 - accuracy: 0.5587 - val_loss: 0.6703 - val_accuracy: 0.6058\n",
      "Epoch 2/10\n",
      "6524/6524 [==============================] - 270s 41ms/step - loss: 0.6856 - accuracy: 0.5647 - val_loss: 0.6715 - val_accuracy: 0.6101\n",
      "Epoch 3/10\n",
      "6524/6524 [==============================] - 270s 41ms/step - loss: 0.6824 - accuracy: 0.5737 - val_loss: 0.6724 - val_accuracy: 0.6162\n",
      "Epoch 4/10\n",
      "6524/6524 [==============================] - 270s 41ms/step - loss: 0.6756 - accuracy: 0.5799 - val_loss: 0.6685 - val_accuracy: 0.6174\n",
      "Epoch 5/10\n",
      "6524/6524 [==============================] - 270s 41ms/step - loss: 0.6658 - accuracy: 0.5826 - val_loss: 0.6598 - val_accuracy: 0.6205\n",
      "Epoch 6/10\n",
      "6524/6524 [==============================] - 270s 41ms/step - loss: 0.6699 - accuracy: 0.5823 - val_loss: 0.6699 - val_accuracy: 0.6033\n",
      "Epoch 7/10\n",
      "6524/6524 [==============================] - 273s 42ms/step - loss: 0.6670 - accuracy: 0.5972 - val_loss: 0.6010 - val_accuracy: 0.6800\n",
      "Epoch 8/10\n",
      "6524/6524 [==============================] - 277s 43ms/step - loss: 0.5627 - accuracy: 0.7026 - val_loss: 0.3799 - val_accuracy: 0.8608\n",
      "Epoch 9/10\n",
      "6524/6524 [==============================] - 276s 42ms/step - loss: 0.5902 - accuracy: 0.6663 - val_loss: 0.5790 - val_accuracy: 0.7474\n",
      "Epoch 10/10\n",
      "6524/6524 [==============================] - 276s 42ms/step - loss: 0.4174 - accuracy: 0.8242 - val_loss: 0.2323 - val_accuracy: 0.9191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f8ad2ce0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=1, validation_data=(X_test_reshaped, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 3s 53ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       649\n",
      "           1       0.95      0.92      0.93       982\n",
      "\n",
      "    accuracy                           0.92      1631\n",
      "   macro avg       0.91      0.92      0.92      1631\n",
      "weighted avg       0.92      0.92      0.92      1631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred = model.predict(X_test_reshaped)\n",
    "labels_pred = np.round(labels_pred.flatten())\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
